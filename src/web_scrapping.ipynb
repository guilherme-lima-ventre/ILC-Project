{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bs4\n",
    "# %pip install requests\n",
    "# %pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ({'User-Agent':\n",
    "\t\t\t'Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "\t\t\tAppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "\t\t\tChrome/90.0.4430.212 Safari/537.36',\n",
    "\t\t\t'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "# user define function\n",
    "# Scrape the data\n",
    "def getdata(url):\n",
    "\tr = requests.get(url, headers=HEADERS)\n",
    "\treturn r.text\n",
    "\n",
    "\n",
    "def html_code(url):\n",
    "\t# pass the url\n",
    "\t# into getdata function\n",
    "\thtmldata = getdata(url)\n",
    "\tsoup = BeautifulSoup(htmldata, 'html.parser')\n",
    "\n",
    "\t# display html code\n",
    "\treturn (soup)\n",
    "\n",
    "# Info da pessoa\n",
    "\n",
    "def cus_data(soup):\n",
    "    # find the Html tag\n",
    "    # with find()\n",
    "    # and convert into string\n",
    "    data_str = \"\"\n",
    "    cus_list = []\n",
    "  \n",
    "    for item in soup.find_all(\"span\", class_=\"a-profile-name\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "        cus_list.append(data_str)\n",
    "        data_str = \"\"\n",
    "    del cus_list[0]\n",
    "    del cus_list[0]\n",
    "    return cus_list\n",
    "\n",
    "# Review da pessoa\n",
    "\n",
    "def cus_rev(soup):\n",
    "    # find the Html tag\n",
    "    # with find()\n",
    "    # and convert into string\n",
    "    data_str = \"\"\n",
    "  \n",
    "    for item in soup.find_all(\"span\", class_=\"a-size-base review-text review-text-content\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "  \n",
    "    result = data_str.split(\"\\n\")\n",
    "    return (result)\n",
    "\n",
    "# Data do review\n",
    "\n",
    "def cus_date(soup):\n",
    "    # find the Html tag\n",
    "    # with find()\n",
    "    # and convert into string\n",
    "    data_str = \"\"\n",
    "    cus_dates = []\n",
    "  \n",
    "    for item in soup.find_all(\"span\", class_=\"a-size-base a-color-secondary review-date\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "        cus_dates.append(data_str)\n",
    "        data_str = \"\"\n",
    "    del cus_dates[0]\n",
    "    del cus_dates[0]\n",
    "    return cus_dates\n",
    "\n",
    "# Info do comentário (rate, titulo, verificacao)\n",
    "\n",
    "def cus_info(soup):\n",
    "    # find the Html tag\n",
    "    # with find()\n",
    "    # and convert into string\n",
    "    data_str = \"\"\n",
    "    cus_info = []\n",
    "  \n",
    "    for item in soup.find_all(\"a\", class_=\"a-link-normal\"):\n",
    "        data_str = data_str + item.get_text()\n",
    "        cus_info.append(data_str)\n",
    "        data_str = \"\"\n",
    "    return cus_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Reviews Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = 'https://www.amazon.com.br/Fire-TV-Stick-Streaming/product-reviews/B08C1K6LB2/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber='\n",
    "urls = []\n",
    "for i in range(1,31):\n",
    "  urls.append(url_template+str(i))\n",
    "\n",
    "# Data de acesso 03/12/2022\n",
    "# Região de acesso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_produto = \"https://www.amazon.com.br/Fire-TV-Stick-Streaming/dp/B08C1K6LB2?pd_rd_w=enHGE&content-id=amzn1.sym.ccd42964-5498-4dd6-ba8b-06c2e8dba67a&pf_rd_p=ccd42964-5498-4dd6-ba8b-06c2e8dba67a&pf_rd_r=G9T7RD41H1ZGXWEGCDN8&pd_rd_wg=8SzpO&pd_rd_r=137ad4bc-da2b-45f1-b918-5815b2233488&pd_rd_i=B08C1K6LB2&psc=1&ref_=pd_bap_d_grid_rp_0_1_i\"\n",
    "cus_res = []\n",
    "rev_data = []\n",
    "rev_result = []\n",
    "rev_date = []\n",
    "acces_date = '03 de dezembro de 2022'\n",
    "acces_reg = 'Brasil'\n",
    "acces_link = []\n",
    "cus_rates = []\n",
    "cus_rates_num = []\n",
    "cus_titles = []\n",
    "cus_checks = []\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "  soup = html_code(url)\n",
    "  rev_data = rev_data + cus_rev(soup)\n",
    "  cus_res = cus_res + cus_data(soup)\n",
    "  rev_date = rev_date + cus_date(soup)\n",
    "  cus_infos = cus_info(soup)\n",
    "\n",
    "  cus_infos = cus_infos[25:65]\n",
    "  rates = list(range(0,40,4))\n",
    "  titles = list(range(1,40,4))\n",
    "  checks = list(range(2,40,4))\n",
    "\n",
    "  rtc = zip(rates, titles, checks)\n",
    "\n",
    "  for r, t, c in rtc:\n",
    "    \n",
    "    cus_rates.append(cus_infos[r])\n",
    "    cus_rates_num.append(float(cus_rates[-1].split()[0].replace(',', '.')))\n",
    "\n",
    "    cus_titles.append(cus_infos[t].strip('\\n'))\n",
    "\n",
    "    cus_checks.append(cus_infos[c])\n",
    "\n",
    "for i in rev_data:\n",
    "    if i == \"\":\n",
    "        pass\n",
    "    else:\n",
    "        rev_result.append(i)\n",
    "while len(rev_result) < len(cus_res):\n",
    "  rev_result.append('')\n",
    "\n",
    "for i in range(len(cus_res)):\n",
    "  acces_link.append(urls[i//10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(cus_res))\n",
    "print(len(rev_result))\n",
    "print(len(rev_date))\n",
    "print(len(acces_link))\n",
    "print(len(cus_rates))\n",
    "print(len(cus_rates_num))\n",
    "print(len(cus_titles))\n",
    "print(len(cus_checks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset to store metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadados = pd.DataFrame({\n",
    "  'Nome': cus_res,\n",
    "  'Rating': cus_rates,\n",
    "  'Num Rating': cus_rates_num,\n",
    "  'Título': cus_titles,\n",
    "  'Comentário': rev_result,\n",
    "  'Data do comentário': rev_date,\n",
    "  'Data de acesso': acces_date,\n",
    "  'Link de acesso': acces_link,\n",
    "  'Região do comentário': acces_reg,\n",
    "  'Vericidade da compra': cus_checks\n",
    "})\n",
    "metadados.drop_duplicates(inplace=True)\n",
    "metadados.dropna(inplace=True)\n",
    "\n",
    "# Removendo comentários nulos\n",
    "null_comments = metadados['Comentário'] == ''\n",
    "metadados = metadados[~null_comments]\n",
    "\n",
    "metadados.reset_index(inplace=True)\n",
    "metadados.rename(columns={'index': 'id'}, inplace=True)\n",
    "metadados.to_excel('../data/metadados.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd86c2ca81e94e9671e6a00c1151869a281542444b464bd149dcb3cefa24f424"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
